{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLW2019_H3_night_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5CaVKf4P0Chp",
        "colab_type": "code",
        "outputId": "791d7a5f-914d-47c7-c6c8-c4a61aeeeed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from random import shuffle\n",
        "from google.colab import files, drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Nm4X6y18kJj",
        "colab_type": "code",
        "outputId": "b17d8cf0-01a6-4ab4-8e0b-09a68b255db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# mounting google drive to notebook, gaining data straight from it\n",
        "# needs the password authorization\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "91pTkL9eyNoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# paths to both classes of image data\n",
        "condition_path = '/content/drive/My Drive/ColabNotebooks/night_depression_image_data/condition'\n",
        "control_path = '/content/drive/My Drive/ColabNotebooks/night_depression_image_data/control'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daksHaSryji9",
        "colab_type": "code",
        "outputId": "cf01bb83-7798-47ad-85f6-bb2d0e10526d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "file_list_cont = []\n",
        "file_list_cond = []\n",
        "\n",
        "for f in os.listdir(condition_path):\n",
        "    file_list_cond.append(os.path.join(condition_path, f))\n",
        "\n",
        "for f in os.listdir(control_path):\n",
        "    file_list_cont.append(os.path.join(control_path, f))\n",
        "\n",
        "# counting 20% of each class \n",
        "n_test_cond = int(0.2*(len(file_list_cond)))\n",
        "n_test_cont = int(0.2*(len(file_list_cont)))\n",
        "\n",
        "random.shuffle(file_list_cond)\n",
        "random.shuffle(file_list_cont)\n",
        "\n",
        "print(\"20% of condition class is \" + str(n_test_cond) + \" instances\")\n",
        "print(\"20% of control class is \" + str(n_test_cont) + \" instances\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20% of condition class is 76 instances\n",
            "20% of control class is 144 instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHCv75s10esC",
        "colab_type": "code",
        "outputId": "65aa9d08-9a75-4e94-fea1-ebfeac35461d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "\n",
        "# assesing 20% of each class to test, and the rest to train \n",
        "for d in range(n_test_cond):\n",
        "  test_data.append(file_list_cond[d])\n",
        "  del file_list_cond[d]\n",
        "\n",
        "for d in range(n_test_cont):\n",
        "  test_data.append(file_list_cont[d])\n",
        "  del file_list_cont[d]\n",
        "  \n",
        "train_data = file_list_cond + file_list_cont\n",
        "\n",
        "print(\"Test dataset has \" + str(len(test_data)) + \" of instances.\")\n",
        "print(\"Train dataset has \" + str(len(train_data)) + \" of instances.\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset has 220 of instances.\n",
            "Train dataset has 886 of instances.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jWdlBPi15Dn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# makes a label (\"control\"/\"condition\") to every image after it's name\n",
        "def one_hot_label(img):\n",
        "  label = img.split('_')[5]\n",
        "  if label == 'condition':\n",
        "    ohl = np.array([1,0])\n",
        "  elif label == 'control':\n",
        "    ohl = np.array([0,1])\n",
        "  return ohl\n",
        "\n",
        "# load the test image and rescale to force later processing, append to array with the label\n",
        "def test_data_with_label():\n",
        "  test_images = []\n",
        "  for i in test_data:\n",
        "    path = os.path.join(i)\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (64,64))\n",
        "    test_images.append([np.array(img), one_hot_label(i)])\n",
        "  return test_images\n",
        "\n",
        "# load the train image and rescale to force later processing, append to array with the label\n",
        "def train_data_with_label():\n",
        "  train_images = []\n",
        "  for i in train_data:\n",
        "    path = os.path.join(i)\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (64,64))\n",
        "    train_images.append([np.array(img), one_hot_label(i)])\n",
        "  return train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tU5LNyST6pyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# usig functions to asses arrays with the image binary data and the label\n",
        "training_images = train_data_with_label()\n",
        "testing_images = test_data_with_label()\n",
        "tr_img_data = np.array([i[0] for i in training_images]).reshape(-1,64,64,1)\n",
        "tr_lbl_data = np.array([i[1] for i in training_images])\n",
        "tst_img_data = np.array([i[0] for i in testing_images]).reshape(-1,64,64,1)\n",
        "tst_lbl_data = np.array([i[1] for i in testing_images])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nTcXb1u7Xtv",
        "colab_type": "code",
        "outputId": "dc8b799c-34e5-4ecd-8563-e2bae71e9a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# LAYERS\n",
        "# first layer made from ... \n",
        "model.add(InputLayer(input_shape=[64,64,1]))\n",
        "# first convolution, we can adjust the number of kernels & filters\n",
        "model.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "# first poolong\n",
        "model.add(MaxPool2D(pool_size=5,padding='same'))    \n",
        "\n",
        "# second layer made from ... \n",
        "model.add(Conv2D(filters=64,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=64,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=5,padding='same')) \n",
        "\n",
        "# third layer made from ... \n",
        "model.add(Conv2D(filters=128,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=128,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=5,padding='same')) \n",
        "\n",
        "# INTERPRETATION\n",
        "# in case of overlearning, drop it out at 0.25 rate\n",
        "model.add(Dropout(0.25))\n",
        "# flattening the image between consecutive convolutional layers\n",
        "model.add(Flatten())\n",
        "# first neuron description, 512 neurons \n",
        "model.add(Dense(512,activation='relu'))\n",
        "# in case of overlearning, drop it out at 0.5 rate\n",
        "model.add(Dropout(0.5))\n",
        "# second neuron description, 2 neurons, 'softmax' to create the probabilities of each of the class o be a class of that instance \n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "#LEARNING\n",
        "# tool for the learning, categorical crossentropy for the binary classification\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#TRAINING\n",
        "#epochs - number of learning iterations, \n",
        "model.fit(x=tr_img_data, y=tr_lbl_data, epochs=50, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "886/886 [==============================] - 2s 2ms/step - loss: 0.8658 - acc: 0.5914\n",
            "Epoch 2/50\n",
            "886/886 [==============================] - 1s 689us/step - loss: 0.6451 - acc: 0.6524\n",
            "Epoch 3/50\n",
            "886/886 [==============================] - 1s 685us/step - loss: 0.6425 - acc: 0.6512\n",
            "Epoch 4/50\n",
            "886/886 [==============================] - 1s 684us/step - loss: 0.6244 - acc: 0.6580\n",
            "Epoch 5/50\n",
            "886/886 [==============================] - 1s 695us/step - loss: 0.6117 - acc: 0.6591\n",
            "Epoch 6/50\n",
            "886/886 [==============================] - 1s 690us/step - loss: 0.6215 - acc: 0.6580\n",
            "Epoch 7/50\n",
            "886/886 [==============================] - 1s 690us/step - loss: 0.5914 - acc: 0.6648\n",
            "Epoch 8/50\n",
            "886/886 [==============================] - 1s 685us/step - loss: 0.5819 - acc: 0.6716\n",
            "Epoch 9/50\n",
            "886/886 [==============================] - 1s 684us/step - loss: 0.5569 - acc: 0.6930\n",
            "Epoch 10/50\n",
            "886/886 [==============================] - 1s 680us/step - loss: 0.5623 - acc: 0.6761\n",
            "Epoch 11/50\n",
            "886/886 [==============================] - 1s 693us/step - loss: 0.5340 - acc: 0.7156\n",
            "Epoch 12/50\n",
            "886/886 [==============================] - 1s 692us/step - loss: 0.5177 - acc: 0.7336\n",
            "Epoch 13/50\n",
            "886/886 [==============================] - 1s 686us/step - loss: 0.5020 - acc: 0.7449\n",
            "Epoch 14/50\n",
            "886/886 [==============================] - 1s 700us/step - loss: 0.5195 - acc: 0.7133\n",
            "Epoch 15/50\n",
            "886/886 [==============================] - 1s 694us/step - loss: 0.4644 - acc: 0.7833\n",
            "Epoch 16/50\n",
            "886/886 [==============================] - 1s 693us/step - loss: 0.4224 - acc: 0.8205\n",
            "Epoch 17/50\n",
            "886/886 [==============================] - 1s 699us/step - loss: 0.3834 - acc: 0.8228\n",
            "Epoch 18/50\n",
            "886/886 [==============================] - 1s 670us/step - loss: 0.3086 - acc: 0.8792\n",
            "Epoch 19/50\n",
            "886/886 [==============================] - 1s 702us/step - loss: 0.3220 - acc: 0.8544\n",
            "Epoch 20/50\n",
            "886/886 [==============================] - 1s 690us/step - loss: 0.2458 - acc: 0.9041\n",
            "Epoch 21/50\n",
            "886/886 [==============================] - 1s 692us/step - loss: 0.2418 - acc: 0.9131\n",
            "Epoch 22/50\n",
            "886/886 [==============================] - 1s 698us/step - loss: 0.1676 - acc: 0.9413\n",
            "Epoch 23/50\n",
            "886/886 [==============================] - 1s 690us/step - loss: 0.1501 - acc: 0.9470\n",
            "Epoch 24/50\n",
            "886/886 [==============================] - 1s 691us/step - loss: 0.1182 - acc: 0.9616\n",
            "Epoch 25/50\n",
            "886/886 [==============================] - 1s 689us/step - loss: 0.1265 - acc: 0.9526\n",
            "Epoch 26/50\n",
            "886/886 [==============================] - 1s 706us/step - loss: 0.1209 - acc: 0.9605\n",
            "Epoch 27/50\n",
            "886/886 [==============================] - 1s 689us/step - loss: 0.1159 - acc: 0.9628\n",
            "Epoch 28/50\n",
            "886/886 [==============================] - 1s 678us/step - loss: 0.1073 - acc: 0.9628\n",
            "Epoch 29/50\n",
            "886/886 [==============================] - 1s 695us/step - loss: 0.1240 - acc: 0.9582\n",
            "Epoch 30/50\n",
            "886/886 [==============================] - 1s 689us/step - loss: 0.0952 - acc: 0.9661\n",
            "Epoch 31/50\n",
            "886/886 [==============================] - 1s 687us/step - loss: 0.0878 - acc: 0.9740\n",
            "Epoch 32/50\n",
            "886/886 [==============================] - 1s 701us/step - loss: 0.0758 - acc: 0.9740\n",
            "Epoch 33/50\n",
            "886/886 [==============================] - 1s 694us/step - loss: 0.0824 - acc: 0.9752\n",
            "Epoch 34/50\n",
            "886/886 [==============================] - 1s 691us/step - loss: 0.0633 - acc: 0.9763\n",
            "Epoch 35/50\n",
            "886/886 [==============================] - 1s 685us/step - loss: 0.0888 - acc: 0.9763\n",
            "Epoch 36/50\n",
            "886/886 [==============================] - 1s 689us/step - loss: 0.0698 - acc: 0.9763\n",
            "Epoch 37/50\n",
            "886/886 [==============================] - 1s 685us/step - loss: 0.0761 - acc: 0.9774\n",
            "Epoch 38/50\n",
            "886/886 [==============================] - 1s 686us/step - loss: 0.0760 - acc: 0.9763\n",
            "Epoch 39/50\n",
            "886/886 [==============================] - 1s 686us/step - loss: 0.0794 - acc: 0.9763\n",
            "Epoch 40/50\n",
            "886/886 [==============================] - 1s 682us/step - loss: 0.0629 - acc: 0.9797\n",
            "Epoch 41/50\n",
            "886/886 [==============================] - 1s 685us/step - loss: 0.0703 - acc: 0.9763\n",
            "Epoch 42/50\n",
            "886/886 [==============================] - 1s 693us/step - loss: 0.0896 - acc: 0.9661\n",
            "Epoch 43/50\n",
            "886/886 [==============================] - 1s 691us/step - loss: 0.1150 - acc: 0.9639\n",
            "Epoch 44/50\n",
            "886/886 [==============================] - 1s 688us/step - loss: 0.0982 - acc: 0.9729\n",
            "Epoch 45/50\n",
            "886/886 [==============================] - 1s 684us/step - loss: 0.0646 - acc: 0.9808\n",
            "Epoch 46/50\n",
            "886/886 [==============================] - 1s 688us/step - loss: 0.0641 - acc: 0.9808\n",
            "Epoch 47/50\n",
            "886/886 [==============================] - 1s 688us/step - loss: 0.0543 - acc: 0.9842\n",
            "Epoch 48/50\n",
            "886/886 [==============================] - 1s 699us/step - loss: 0.0480 - acc: 0.9842\n",
            "Epoch 49/50\n",
            "886/886 [==============================] - 1s 692us/step - loss: 0.0402 - acc: 0.9842\n",
            "Epoch 50/50\n",
            "886/886 [==============================] - 1s 689us/step - loss: 0.0386 - acc: 0.9865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91e8037f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "PEqIeWsf0Doe",
        "colab_type": "code",
        "outputId": "cd37d708-4e1e-4d44-92a7-06196d242175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_76 (Conv2D)           (None, 64, 64, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 64, 64, 32)        25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 13, 13, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 13, 13, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 3, 3, 128)         204928    \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 3, 3, 128)         409728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 861,922\n",
            "Trainable params: 861,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M6qjWzaJKLHA",
        "colab_type": "code",
        "outputId": "baa93186-8050-419b-9a3f-5dd654057e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# testing phase\n",
        "score = model.evaluate(tr_img_data, tr_lbl_data, verbose=0)\n",
        "\n",
        "# second element is 'accuracy'\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.035844031473642485, 0.9853273137697517]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "pUA193GM5NEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gained a better accuracy (from 0.656 to 0.985 by changing to CPU hardware accelerator & adding the second Conv2D to each layer)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
